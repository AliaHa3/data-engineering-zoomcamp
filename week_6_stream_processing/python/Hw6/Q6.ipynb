{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ded558-b8d9-4438-9c1b-14942d6b2b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,org.apache.spark:spark-avro_2.12:3.3.1 pyspark-shell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed6537-ccc1-423d-bba6-18a0d6069a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark-Notebook\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038c002-21d3-49c7-a1ae-1a3620b646ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_ride_from_kafka_message(df_raw, schema):\n",
    "    \"\"\" take a Spark Streaming df and parse value col based on <schema>, return streaming df cols in schema \"\"\"\n",
    "    assert df_raw.isStreaming is True, \"DataFrame doesn't receive streaming data\"\n",
    "\n",
    "    df = df_raw.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "    # split attributes to nested array in one Column\n",
    "    col = F.split(df['value'], ', ')\n",
    "\n",
    "    # expand col to multiple top-level columns\n",
    "    for idx, field in enumerate(schema):\n",
    "        df = df.withColumn(field.name, col.getItem(idx).cast(field.dataType))\n",
    "    return df.select([field.name for field in schema])\n",
    "\n",
    "# %%\n",
    "def sink_console(df, output_mode: str = 'complete', processing_time: str = '5 seconds'):\n",
    "    write_query = df.writeStream \\\n",
    "        .outputMode(output_mode) \\\n",
    "        .trigger(processingTime=processing_time) \\\n",
    "        .format(\"console\") \\\n",
    "        .option(\"truncate\", False) \\\n",
    "        .start()\n",
    "    return write_query # pyspark.sql.streaming.StreamingQuery\n",
    "\n",
    "# %%\n",
    "def sink_memory(df, query_name, query_template):\n",
    "    write_query = df \\\n",
    "        .writeStream \\\n",
    "        .queryName(query_name) \\\n",
    "        .format('memory') \\\n",
    "        .start()\n",
    "    query_str = query_template.format(table_name=query_name)\n",
    "    query_results = spark.sql(query_str)\n",
    "    return write_query, query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d75be-f8a4-4a9d-a779-56c3d7021acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_kafka_green_raw = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092,broker:29092\") \\\n",
    "    .option(\"subscribe\", \"green_rides_csv\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint\") \\\n",
    "    .load()\n",
    "\n",
    "# %%\n",
    "df_kafka_green_raw.printSchema()\n",
    "\n",
    "# %%\n",
    "GREEN_RIDES_SCHEMA = T.StructType(\n",
    "    [\n",
    "     T.StructField(\"vendor_id\", T.IntegerType()),\n",
    "     T.StructField('pickup_datetime', T.TimestampType()),\n",
    "     T.StructField('dropoff_datetime', T.TimestampType()),\n",
    "     T.StructField(\"store_and_fwd_flag\", T.StringType()),\n",
    "     T.StructField(\"RatecodeID\", T.IntegerType()),\n",
    "     T.StructField(\"PULocationID\", T.IntegerType()),\n",
    "     T.StructField(\"DOLocationID\", T.IntegerType()),\n",
    "     T.StructField(\"passenger_count\", T.IntegerType())\n",
    "     ])\n",
    "\n",
    "# %%\n",
    "df_green_rides = parse_ride_from_kafka_message(df_raw=df_kafka_green_raw, schema=GREEN_RIDES_SCHEMA)\n",
    "df_green_rides.printSchema()\n",
    "\n",
    "# %%\n",
    "# query_name = 'green_PUlocationID_popularity'\n",
    "# query_template = 'select PUlocationID,count(*) as count_rides from {table_name} group by PUlocationID order by count_rides desc'\n",
    "# write_query, df_green_PUlocationID_popularity = sink_memory(df=df_green_rides, query_name=query_name, query_template=query_template)\n",
    "# print(type(write_query)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2d577-bc90-4347-985a-983ddff32a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_kafka_fhv_raw = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092,broker:29092\") \\\n",
    "    .option(\"subscribe\", \"fhv_rides_csv\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint\") \\\n",
    "    .load()\n",
    "\n",
    "# %%\n",
    "df_kafka_fhv_raw.printSchema()\n",
    "\n",
    "# %%\n",
    "FHV_RIDES_SCHEMA =T.StructType(\n",
    "    [\n",
    "     T.StructField(\"dispatching_base_num\", T.StringType()),\n",
    "     T.StructField('pickup_datetime', T.TimestampType()),\n",
    "     T.StructField('dropoff_datetime', T.TimestampType()),\n",
    "     T.StructField(\"PUlocationID\", T.IntegerType()),\n",
    "     T.StructField(\"DOlocationID\", T.IntegerType()),\n",
    "     T.StructField(\"SR_Flag\", T.StringType()),\n",
    "     T.StructField(\"Affiliated_base_number\", T.StringType()),\n",
    "     ])\n",
    "\n",
    "# %%\n",
    "df_fhv_rides = parse_ride_from_kafka_message(df_raw=df_kafka_fhv_raw, schema=FHV_RIDES_SCHEMA)\n",
    "df_fhv_rides.printSchema()\n",
    "\n",
    "# %%\n",
    "# query_name = 'fhv_PUlocationID_popularity'\n",
    "# query_template = 'select PUlocationID,count(*) as count_rides from {table_name} group by PUlocationID order by count_rides desc'\n",
    "# write_query, df_fhv_PUlocationID_popularity = sink_memory(df=df_fhv_rides, query_name=query_name, query_template=query_template)\n",
    "# print(type(write_query)) # pyspark.sql.streaming.StreamingQuery\n",
    "# write_query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83393e43-948c-48e0-87c6-4e60cd2ae8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataframe_to_kafka_sink(df, value_columns, key_column=None):\n",
    "    columns = df.columns\n",
    "    df = df.withColumn(\"value\", F.concat_ws(', ',*value_columns))    \n",
    "    if key_column:\n",
    "        df = df.withColumnRenamed(key_column,\"key\")\n",
    "        df = df.withColumn(\"key\",df.key.cast('string'))\n",
    "    return df.select(['key', 'value'])\n",
    "    \n",
    "def sink_kafka(df, topic, output_mode='append'):\n",
    "    write_query = df.writeStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092,broker:29092\") \\\n",
    "        .outputMode(output_mode) \\\n",
    "        .option(\"topic\", topic) \\\n",
    "        .option(\"checkpointLocation\", \"checkpoint\") \\\n",
    "        .start()\n",
    "    return write_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad538149-5192-4109-a755-45b64d76153d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC_RIDES_ALL = \"rides_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c5195-e3c6-459e-810e-6bbb6754d32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_green_messages = prepare_dataframe_to_kafka_sink(df=df_green_rides,\n",
    "                                                      value_columns=['PUlocationID','DOLocationID'], key_column='PULocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385217a0-ccb9-4ca9-94a4-a2b86cb10eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_sink_green_query = sink_kafka(df=df_green_messages, topic=TOPIC_RIDES_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f8abc-fe7e-408c-a5bb-d1429fb0a67b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_sink_green_query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3fb829-f229-4aca-a49f-8ad2ba619d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fhv_messages = prepare_dataframe_to_kafka_sink(df=df_fhv_rides,\n",
    "                                                      value_columns=['PUlocationID','DOLocationID'], key_column='PULocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f5a66-550b-47d8-b39e-aaccbbef096b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_sink_fhv_query = sink_kafka(df=df_fhv_messages, topic=TOPIC_RIDES_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68bd97-031e-4ad9-a08b-b1f345478627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kafka_sink_fhv_query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142a46f-2036-4723-8610-926cc7d717fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309d300-cae0-4df0-8ff8-752950fd7816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_kafka_all_raw = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092,broker:29092\") \\\n",
    "    .option(\"subscribe\", \"rides_all\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint\") \\\n",
    "    .load()\n",
    "\n",
    "# %%\n",
    "df_kafka_all_raw.printSchema()\n",
    "\n",
    "# %%\n",
    "all_RIDES_SCHEMA =T.StructType(\n",
    "    [\n",
    "     T.StructField(\"PUlocationID\", T.IntegerType()),\n",
    "     T.StructField(\"DOlocationID\", T.IntegerType())\n",
    "     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779259a-552e-4d3d-9b8a-486966993eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "df_all_rides = parse_ride_from_kafka_message(df_raw=df_kafka_all_raw, schema=all_RIDES_SCHEMA)\n",
    "df_all_rides.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa685a-fa1c-4aab-8744-bd3955b11181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "query_name = 'PUlocationID_popularity'\n",
    "query_template = 'select PUlocationID,count(*) as count_rides from {table_name} group by PUlocationID order by count_rides desc'\n",
    "write_query, df_PUlocationID_popularity = sink_memory(df=df_all_rides, query_name=query_name, query_template=query_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f51f21-a752-4304-b02b-e56ffd1831d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(write_query)) # pyspark.sql.streaming.StreamingQuery\n",
    "write_query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16d474-feab-4e8e-b910-93980040661f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_PUlocationID_popularity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9510e1-4c96-4003-908d-2a2205d5e416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a86edb-8d92-459f-a747-964c0cc62725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
